#!/usr/bin/env python
# coding: utf-8

# # Case Salt RH

# # Modelo machine learning - Previs√£o de casas - AMES

# # Exploratory Data Analysis (EDA)
# 

# **--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**

# **Desafio T√©cnico**
# 
# - **Quest√£o 1**
# 
# Quando voc√™ obt√©m seus dados pela primeira vez, √© muito tentador come√ßar imediatamente a ajustar os modelos e avaliar o desempenho deles. No entanto, antes de come√ßar a modelar, √© absolutamente essencial explorar a estrutura dos dados e os relacionamentos entre as vari√°veis no conjunto de dados.
# Fa√ßa um EDA detalhado do conjunto de dados ames_train, para aprender sobre a estrutura dos dados e os relacionamentos entre as vari√°veis no conjunto de dados.
# 
# 
# - **Quest√£o 2**
# 
# Depois de ter explorado completamente, certifique-se de criar pelo menos quatro gr√°ficos que voc√™ achou mais informativos durante seu processo de EDA e explique brevemente o que voc√™ aprendeu com cada um (por que voc√™ achou cada informativo).
# 
# 
# - **Quest√£o 3**
# 
# Na constru√ß√£o de um modelo, geralmente √© √∫til come√ßar criando um modelo inicial simples e intuitivo com base nos resultados da an√°lise explorat√≥ria de dados. Voc√™ pode sentir vontade de apresentar habilidades estat√≠sticas mais avan√ßadas. Por esse motivo, estamos fornecendo dados de teste no conjunto de dados ames_test para que voc√™ possa construir um modelo simples para prever os pre√ßos das casas com base nos dados dispon√≠veis no conjunto de dados de treinamento. Use sua imagina√ß√£o.
# 

# **Nota: O objetivo n√£o √© identificar o ‚Äúmelhor‚Äù modelo poss√≠vel, mas escolher um ponto de partida razo√°vel e compreens√≠vel**

# # Regras de Envio
# 
# Para que o seu desafio seja analisado, voc√™ dever√° atender √†s seguintes regras:
# 
# - Respeitar a data limite informada no email
# 
# - Fazer um projeto utilizando a linguagem python
# 
# - O c√≥digo dever√° ser entregue como um notebook no formato .ipynb, identificando adequadamente as quest√µes, com coment√°rios e explica√ß√µes.
# 

# # Avalia√ß√£o
# 
# Iremos avaliar a forma que voc√™ resolveu as quest√µes, sua criatividade, insights e passos que tomou para obten√ß√£o de resultados, assim como os coment√°rios e forma como desenvolveu os c√≥digos. Dessa forma sugerimos a originalidade e criatividade para resolu√ß√£o das quest√µes.
# 

# **--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**

# # 0 - Importa√ß√£o das bibliotecas

# In[1]:


# Vers√£o do python
from platform import python_version

print('Vers√£o python neste Jupyter Notebook:', python_version())


# In[2]:


# Importa√ß√£o das bibliotecas 

import pandas as pd # Pandas carregamento csv
import numpy as np # Numpy para carregamento c√°lculos em arrays multidimensionais

# Visualiza√ß√£o de dados
import seaborn as sns
import matplotlib as m
import matplotlib as mpl
import matplotlib.pyplot as plt
import plotly
import plotly.express as px

# Carregar as vers√µes das bibliotecas
import watermark

# Warnings retirar alertas 
import warnings
warnings.filterwarnings("ignore")


# In[3]:


# Vers√µes das bibliotecas

get_ipython().run_line_magic('reload_ext', 'watermark')
get_ipython().run_line_magic('watermark', '-a "Vers√µes das bibliotecas" --iversions')


# In[4]:


# Configura√ß√£o para os gr√°ficos largura e layout dos graficos

plt.rcParams["figure.figsize"] = (25, 20)

plt.style.use('fivethirtyeight')
pd.set_option('display.expand_frame_repr', False)
pd.set_option('display.max_columns', 500)
pd.set_option('display.width', 1000)

m.rcParams['axes.labelsize'] = 25
m.rcParams['xtick.labelsize'] = 25
m.rcParams['ytick.labelsize'] = 25
m.rcParams['text.color'] = 'k'


# # 0.1) Base de dados

# In[5]:


# Carregando a base de dados
data_train = pd.read_csv("ames_train.csv", sep = ";")
data_test = pd.read_csv("ames_test.csv", sep = ";")


# # 0.2) Descri√ß√£o dados
# 
# - Verifica√ß√£o de linhas colunas informa√ß√£os dos dados e tipos de vari√°veis. Valores das colunas verficando dados nulos ou vazios.

# In[6]:


# Exibido 5 primeiros dados de data_train

data_train.head()


# In[7]:


# Exibido 5 √∫ltimos dados de data_train

data_train.tail()


# In[8]:


# Exibido 5 primeiros dados de data_test

data_test.head()


# In[9]:


# Exibido 5 √∫ltimos dados de data_train

data_test.tail()


# In[10]:


# N√∫mero de linhas e colunas

data_train.shape


# In[11]:


# Verificando informa√ß√µes das variaveis

data_train.info()


# In[12]:


# Exibido tipos de dados

data_train.dtypes


# In[13]:


# Total de colunas e linhas - data_train

print("N√∫meros de linhas: {}" .format(data_train.shape[0]))
print("N√∫meros de colunas: {}" .format(data_train.shape[1]))


# In[14]:


# Total de colunas e linhas - data_test

print("N√∫meros de linhas: {}" .format(data_test.shape[0]))
print("N√∫meros de colunas: {}" .format(data_test.shape[1]))


# In[15]:


# Exibindo valores ausentes e valores √∫nicos

print("\nMissing values :  ", data_train.isnull().sum().values.sum())
print("\nUnique values :  \n",data_train.nunique())


# In[16]:


# Exibindo valores ausentes e valores √∫nicos

print("\nMissing values :  ", data_test.isnull().sum().values.sum())
print("\nUnique values :  \n",data_test.nunique())


# # 0.3) - Limpeza da base de dados

# In[17]:


# Dados faltantes coluna √≥bitos

data = data_train[data_train["price"].notnull()]
data.isna().sum()


# In[18]:


# Removendo dados ausentes do dataset 

data = data_train.dropna()
data_train.head()


# In[19]:


# Sum() Retorna a soma dos valores sobre o eixo solicitado
# Isna() Detecta valores ausentes

data_train.isna().sum()


# In[20]:


# Retorna a soma dos valores sobre o eixo solicitado
# Detecta valores n√£o ausentes para um objeto semelhante a uma matriz.

data_train.notnull().sum()


# In[21]:


# Total de n√∫mero duplicados

data_train.duplicated()


# In[22]:


# Dados faltantes

data_train.fillna(0, inplace=True)
data_train.head()


# In[23]:


# Per√≠odos faltantes

sorted(data_train['price'].unique())


# # Quest√£o 1
# 
# Quando voc√™ obt√©m seus dados pela primeira vez, √© muito tentador come√ßar imediatamente a ajustar os modelos e avaliar o desempenho deles. No entanto, antes de come√ßar a modelar, √© absolutamente essencial explorar a estrutura dos dados e os relacionamentos entre as vari√°veis no conjunto de dados.
# Fa√ßa um EDA detalhado do conjunto de dados ames_train, para aprender sobre a estrutura dos dados e os relacionamentos entre as vari√°veis no conjunto de dados.
# 
# 
# **R**: Primeira etapa que fiz sabe os tipos das vari√°veis n√≥s dados de ames_train, depois uma limpeza dos dados removendo dados nulos, ausentes e dados duplicados, fiz uma estat√≠stica descritiva visualizar como percentil, m√©dia, moda, mediana, depois eu fiz uma distribui√ß√£o normal da coluna pre√ßos do im√≥veis. Uma an√°lise de boxplot verificando poss√≠veis outliers dentro dos dados. 
# 

# # 0.4) Estat√≠stica descritiva

# In[24]:


# Exibindo estat√≠sticas descritivas visualizar alguns detalhes estat√≠sticos b√°sicos como percentil, m√©dia, padr√£o, etc. 
# De um quadro de dados ou uma s√©rie de valores num√©ricos.

data_train.describe().T


# # 0.5) Gr√°fico de distribui√ß√£o normal

# In[25]:


# Gr√°fico distribui√ß√£o normal
plt.figure(figsize=(18.2, 8))

ax = sns.distplot(data_train['price']);
plt.title("Distribui√ß√£o normal", fontsize=20)
plt.xlabel("Pre√ßo do im√≥vel")
plt.ylabel("Total")
plt.axvline(data_train['price'].mean(), color='b')
plt.axvline(data_train['price'].median(), color='r')
plt.axvline(data_train['price'].mode()[0], color='g');
plt.legend(["Media", "Mediana", "Moda"])
plt.show()


# In[85]:


# Verificando os dados no boxplot valor total verificando poss√≠veis outliers

plt.figure(figsize=(18.2, 8))
ax = sns.boxplot(x="Sale.Condition", y="price", data = data_train)
plt.title("Gr√°fico de boxplot - Regi√£o o valor total")
plt.xlabel("Total")
plt.ylabel("Valor total")


# In[27]:


# C√°lculo da m√©dia pre√ßos dos im√≥veis 

media_preco = data_train[['price', 'MS.SubClass']].groupby('price').mean()
media_area = data_train[["area", "price"]].groupby('price').mean()

print("M√©dia de Pre√ßo", media_preco)
print()
print("M√©dia da Idade", media_area)


# # 0.6) Matriz de correla√ß√£o dos dados

# In[28]:


# Matriz correla√ß√£o de pares de colunas, excluindo NA / valores nulos.

corr = data_train.corr()
corr


# In[29]:


# Gr√°fico da matriz de correla√ß√£o

plt.figure(figsize=(60.5,45))
ax = sns.heatmap(data_train.corr(), annot=True, cmap='YlGnBu');
plt.title("Matriz de correla√ß√£o")


# # 0.5) An√°lise de dados

# # Quest√£o 2
# 
# Depois de ter explorado completamente, certifique-se de criar pelo menos quatro gr√°ficos que voc√™ achou mais informativos durante seu processo de EDA e explique brevemente o que voc√™ aprendeu com cada um (por que voc√™ achou cada informativo).
# 
# **R**: Eu escolhei os quarto gr√°ficos como o pre√ßo dos im√≥veis, data de nascimento das pessoas, regi√£o pela condi√ß√£o dos moradores, condi√ß√£o de vinda pelo valor do im√≥vel. Na minha analise no gr√°fico 1 e pre√ßos do im√≥vel √© possivil sabe o valor da venda do valor baixo e alto . No segundo gr√°fico s√©ria nascimento das pessoas que nasceram de 1900 at√© 200 nessa caso podemos observar que nasceram em 1960 comparam im√≥veis idades. No terceiro gr√°fico s√©ria as condi√ß√µes das pessoas que s√£o familiar, solteiros, casados. E no quarto gr√°fico seria a regi√£o aonde as pessoas que comparam os im√≥veis.

# In[30]:


# Observando total dos pre√ßos dos im√≥vel

plt.figure(figsize=(18.2, 8))
sns.histplot(data_train["price"])
plt.title("Pre√ßo do im√≥vel")
plt.xlabel("Valor")
plt.ylabel("Total")


# In[87]:


# Gr√°fico nascimento das pessoas 
plt.figure(figsize=(18.2, 8))

plt.title("Nascimento das pessoas")
ax = sns.histplot(data_train["Year.Built"])
plt.ylabel("Total")
plt.xlabel("Ano")


# In[32]:


# Gr√°fico condi√ß√µes de vinda por valor do im√≥vel
plt.figure(figsize=(25.5, 15))

plt.title("Condi√ß√µes de vinda pelo valor pre√ßo dos im√≥vel")
ax = sns.barplot(x="Yr.Sold", y="price", data = data_train, hue="Sale.Condition")
plt.ylabel("Valor")
plt.xlabel("Imovel vendidos")


# In[33]:


# Regi√£o das vendas dos im√≥veis pela √°rea
plt.figure(figsize=(18.2, 8))

plt.title("√Årea da cidade")
ax = sns.scatterplot(x="area", y="price", data = data_train, hue = "Sale.Condition")
plt.xlabel("Valor dos im√≥veis")
plt.ylabel("Valor")


# In[34]:


# Gr√°fico condi√ß√£o de vida das pessoas 
plt.figure(figsize=(18.2, 8))

plt.title("Condi√ß√£o de venda dos im√≥veis")
sns.countplot(data_train["Sale.Condition"])
plt.xlabel("Condi√ß√£o")
plt.ylabel("Total")


# # 0.6) An√°lise de dados = Univariada

# In[83]:


# Fazendo um comparativo dos dados 

data_train.hist(bins = 25, figsize=(40.2, 35))
plt.title("Gr√°fico de histograma")
plt.show()


# # 0.7) Data Processing
# O processamento de dados come√ßa com os dados em sua forma bruta e os converte em um formato mais leg√≠vel (gr√°ficos, documentos, etc.), dando-lhes a forma e o contexto necess√°rios para serem interpretados por computadores e utilizados.
# 
# Exemplo: Uma letra, um valor num√©rico. Quando os dados s√£o vistos dentro de um contexto e transmite algum significado, tornam-se informa√ß√µes.

# In[89]:


# Tipos dos dados
data_test.dtypes


# In[37]:


# Mundando os tipo de dados de object para inteiros 

data_test['Lot.Area'] = data_test['Lot.Area'].astype(int)
data_test['Yr.Sold'] = data_test['Yr.Sold'].astype(int)
data_test.dtypes


# # 0.8) Feature Engineering
# 
# Praticamente todos os algoritmos de Aprendizado de M√°quina possuem entradas e sa√≠das. As entradas s√£o formadas por colunas de dados estruturados, onde cada coluna recebe o nome de feature, tamb√©m conhecido como vari√°veis independentes ou atributos. Essas features podem ser palavras, peda√ßos de informa√ß√£o de uma imagem, etc. Os modelos de aprendizado de m√°quina utilizam esses recursos para classificar as informa√ß√µes.
# Por exemplo, sedentarismo e fator heredit√°rio s√£o vari√°veis independentes para quando se quer prever se algu√©m vai ter c√¢ncer ou n√£o
# 
# As sa√≠das, por sua vez, s√£o chamadas de vari√°veis dependentes ou classe, e essa √© a vari√°vel que estamos tentando prever. O nosso resultado pode ser 0 e 1 correspondendo a 'N√£o' e 'Sim' respectivamente, que responde a uma pergunta como: "Fulano √© bom pagador?" ou a probabilidade de algu√©m comprar um produto ou n√£o.

# In[38]:


# Importando a biblioteca para pr√©-processamento 

from sklearn.preprocessing import LabelEncoder

for i in data_test.columns:
    if data_test[i].dtype==np.number:
        continue
    data_test[i]= LabelEncoder().fit_transform(data_test[i])
    
data_test.head(4)


# # 0.9) Treino e Teste
# 
# - Treino e teste da base de dados da coluna price e idade

# In[39]:


x = data_test[["Lot.Area", "Yr.Sold"]] # Vari√°vel para treino
y = data_test["price"] # Vari√°vel para teste


# In[40]:


# Total de linhas e colunas dados vari√°vel x
x.shape


# In[41]:


# Total de linhas e colunas dados vari√°vel y
y.shape


# # 10) Escalonamento
# 
# - Escalonamento uma forma de contornar os problemas relacionados √† escala, mantendo a informa√ß√£o estat√≠stica dos dados. O procedimento consiste em realizar uma transforma√ß√£o sobre o conjunto original dos dados de modo que cada vari√°vel apresente m√©dia zero e vari√¢ncia unit√°ria.

# In[42]:


# Importando a biblioteca sklearn para o escalonamneto dos dados

from sklearn.preprocessing import StandardScaler 

scaler_pre = StandardScaler() # Inicializando o escalonamento
scaler_pre_fit_train = scaler_pre.fit_transform(x) # Treinamento com a fun√ß√£o fit_transform com a vari√°vel x
scaler_pre_fit_train # Imprimindo o valor do escalonamento


# # 11) Modelo treinado para x, y valor
# 
# - 20% para os dados de treino
# - 80% para teste
# - Random state igual a zero

# In[43]:


# Importa√ß√£o da biblioteca sklearn para treino e teste do modelo

from sklearn.model_selection import train_test_split 

x_train, x_test, y_train, y_test = train_test_split(x, # Vari√°vel x
                                                    y, # Vari√°vel y
                                                    test_size=0.20, # Divivindo os dados em 20% para treino e 80% para teste
                                                    random_state = 0) # Random state igual a zero


# In[44]:


# Total de linhas e colunas e linhas dos dados de treino x

x_train.shape


# In[45]:


# Total de linhas dos dados de treino y

y_train.shape


# In[46]:


# Total de linhas e colunas dos dados de treino x teste 

x_test.shape


# In[47]:


# Total de linhas e colunas dos dados de treino y teste 

y_test.shape


# # 12) Modelo machine learning 

# # Quest√£o 3
# 
# Na constru√ß√£o de um modelo, geralmente √© √∫til come√ßar criando um modelo inicial simples e intuitivo com base nos resultados da an√°lise explorat√≥ria de dados.
# Voc√™ pode sentir vontade de apresentar habilidades estat√≠sticas mais avan√ßadas. Por esse motivo, estamos fornecendo dados de teste no conjunto de dados ames_test para que voc√™ possa construir um modelo simples para prever os pre√ßos das casas com base nos dados dispon√≠veis no conjunto de dados de treinamento. Use sua imagina√ß√£o.
# 
# **R**: Na constru√ß√£o de um modelo, geralmente √© √∫til come√ßar criando um modelo inicial simples e intuitivo com base nos resultados da an√°lise explorat√≥ria de dados.
# Voc√™ pode sentir vontade de apresentar habilidades estat√≠sticas mais avan√ßadas. Por esse motivo, estamos fornecendo dados de teste no conjunto de dados ames_test para que voc√™ possa construir um modelo simples para prever os pre√ßos das casas com base nos dados dispon√≠veis no conjunto de dados de treinamento. Use sua imagina√ß√£o.
# R: No modelo de machine learning em primeiro fiz o pr√©-processamento dos dados mudando os tipo de dados de float para inteiro. O segundo passo eu fiz feature engineering nos dados na vari√°vel, dependente s√©ria "Price". No terceiro passo que fiz declara as vari√°veis para treino e teste. A outra etapa seria o escalonamento dos dados, transformando a vari√°vel treino para m√©dia zero e vari√¢ncia unit√°ria. Outra etapa treinamento do modelo 20 para treino, 80 para teste. Por √∫ltimo os modelos de machine learning que eu utilizei foi a regress√£o linear, random forest regressor, K-NN regressor, decision tree regressor na minha an√°lise o modelo teve resultado √≥timo foi o Decision Tree Regressor, o segundo Random Forest no primeiro modelo teve uma acur√°cia de 95.60%, o segundo teve 82.58%. E foi utilizado as m√©tricas como RMSE, MAE, MSE, MAPE, R2, n√≥s modelo teve resultados √≥timos.
# A previs√£o dos im√≥veis com a target "Price" prev√™ o valor de im√≥vel pela idade das pessoas. Portanto nesse case tive algumas coisas que aprendi foi modelagem de dados, an√°lise de dados, pr√©-processamento, engenharia de recursos dentro dos dados de ames_test. Nesse case tive uma vis√£o para utilizar modelos de regress√µes.

# **Modelo machine learning 01 - Regress√£o linear**

# In[48]:


# Modelo regress√£o linear - 1
# Importa√ß√£o da biblioteca sklearn o modelo regress√£o linear

from sklearn.linear_model import LinearRegression 

# Nome do algoritmo M.L
model_linear = LinearRegression() 

# Treinamento do modelo
model_linear_fit = model_linear.fit(x_train, y_train)

# Score do modelo
model_linear_score_1 = model_linear.score(x_train, y_train)

# Previs√£o do modelo

model_linear_pred = model_linear.predict(x_test)
model_linear_pred


# In[49]:


# O intercepto representa o efeito m√©dio em tendo todas as vari√°veis explicativas exclu√≠das do modelo. 
# De forma mais simples, o intercepto representa o efeito m√©dio em s√£o iguais a zero.

model_linear.intercept_


# In[50]:


# Os coeficientes de regress√£o  ùõΩ2 ,  ùõΩ3  e  ùõΩ4  s√£o conhecidos como coeficientes parciais de regress√£o ou coeficientes parciais angulares. 
# Considerando o n√∫mero de vari√°veis explicativas de nosso modelo, seu significado seria o seguinte

model_linear.coef_


# In[51]:


# O coeficiente de determina√ß√£o (R¬≤) √© uma medida resumida que diz quanto a linha de regress√£o ajusta-se aos dados. 
# √â um valor entra 0 e 1.

print('R¬≤ = {}'.format(model_linear.score(x_train, y_train).round(2)))


# In[52]:


# Previs√£o do modelo 
pred = model_linear.predict(x_train)
pred2 = y_train - pred
pred2


# In[53]:


# Grafico de regress√£o linear

plt.figure(figsize=(18, 8))
plt.scatter(pred, y_train)
plt.plot(pred, model_linear.predict(x_train), color = "red")
plt.title("Grafico de regress√£o linear", fontsize = 20)
plt.xlabel("Total")
plt.ylabel("Valor dos im√≥veis")
plt.legend(["Pre√ßo", "Im√≥vel"])


# In[54]:


# Gr√°fico de distribui√ß√£o Frequ√™ncias

ax = sns.distplot(pred)
ax.figure.set_size_inches(20, 8)
ax.set_title('Distribui√ß√£o de Frequ√™ncias dos Res√≠duos', fontsize=18)
ax.set_xlabel('Interna√ß√µes', fontsize=14)
ax


# # 13) M√©tricas para o modelo de regress√£o linear

# - RMSE: Raiz do erro quadr√°tico m√©dio 
# - MAE: Erro absoluto m√©dio  
# - MSE: Erro m√©dio quadr√°tico
# - MAPE: Erro Percentual Absoluto M√©dio
# - R2: O R-Quadrado, ou Coeficiente de Determina√ß√£o, √© uma m√©trica que visa expressar a quantidade da varian√ßa dos dados.

# In[55]:


# Importando bibliotecas verifica√ß√µes das m√©tricas 

from math import sqrt
from sklearn.metrics import r2_score
from sklearn.metrics import mean_absolute_percentage_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error

rmse = np.sqrt(mean_squared_error(y_test, model_linear_pred))
mae = mean_absolute_error(y_test, model_linear_pred)
mape = mean_absolute_percentage_error(y_test, model_linear_pred)
mse = mean_squared_error(y_test, model_linear_pred)
r2 = r2_score(y_test, model_linear_pred)

pd.DataFrame([rmse, mae, mse, mape, r2], ['RMSE', 'MAE', 'MSE', "MAPE",'R¬≤'], columns=['Resultado'])


# In[56]:


# Previs√£o dos pre√ßos dos im√≥vel

prev = x_test[0:25]
model_pred = model_linear.predict(prev)[0]
print("Previs√£o do im√≥vel", model_pred)
prev


# # 14) Modelo 02 - Random Forest Regressor

# In[57]:


from sklearn.ensemble import RandomForestRegressor

model_random_forest_regressor = RandomForestRegressor(max_depth=20, random_state=0)
model_random_forest_regressor_fit = model_random_forest_regressor.fit(x_train, y_train)
model_random_forest_regressor_score = model_random_forest_regressor.score(x_train, y_train)

print("Modelo - Random forest regressor score: %.2f" % (model_random_forest_regressor_score * 100))


# In[58]:


model_random_forest_regressor_pred = model_random_forest_regressor.predict(x_test)
model_random_forest_regressor_pred


# In[59]:


# O coeficiente de determina√ß√£o (R¬≤) √© uma medida resumida que diz quanto a linha de regress√£o ajusta-se aos dados. 
# √â um valor entra 0 e 1.

print('R¬≤ = {}'.format(model_random_forest_regressor.score(x_train, y_train).round(2)))


# In[60]:


# Previs√£o do modelo 
pred = model_random_forest_regressor.predict(x_train)
pred2 = y_train - pred
pred2


# In[61]:


# Grafico de regress√£o linear

plt.figure(figsize=(18, 8))
plt.scatter(pred, y_train)
plt.plot(pred, model_random_forest_regressor.predict(x_train), color = "red")
plt.title("Grafico de regress√£o linear", fontsize = 20)
plt.xlabel("Total")
plt.xlabel("Total")
plt.ylabel("Valor dos im√≥veis")
plt.legend(["Im√≥vel", "Pre√ßo"])


# In[62]:


# Gr√°fico de distribui√ß√£o Frequ√™ncias

ax = sns.distplot(pred)
ax.figure.set_size_inches(20, 8)
ax.set_title('Distribui√ß√£o de Frequ√™ncias dos Res√≠duos', fontsize=18)
ax.set_xlabel('Valor', fontsize=14)
ax


# # 15) M√©tricas para o modelo 2 Random Forest Regressor
# 
# - RMSE: Raiz do erro quadr√°tico m√©dio 
# - MAE: Erro absoluto m√©dio  
# - MSE: Erro m√©dio quadr√°tico
# - MAPE: Erro Percentual Absoluto M√©dio
# - R2: O R-Quadrado, ou Coeficiente de Determina√ß√£o, √© uma m√©trica que visa expressar a quantidade da varian√ßa dos dados.

# In[63]:


rmse = np.sqrt(mean_squared_error(y_test, model_random_forest_regressor_pred))
mae = mean_absolute_error(y_test, model_random_forest_regressor_pred)
mape = mean_absolute_percentage_error(y_test, model_random_forest_regressor_pred)
mse = mean_squared_error(y_test, model_random_forest_regressor_pred)
r2 = r2_score(y_test, model_random_forest_regressor_pred)

pd.DataFrame([rmse, mae, mse, mape, r2], ['RMSE', 'MAE', 'MSE', "MAPE",'R¬≤'], columns=['Resultado'])


# In[64]:


# Previs√£o de im√≥vel

prev = x_test[0:25]
model_pred = model_random_forest_regressor.predict(prev)[0]
print("Previs√£o valor do im√≥vel", model_pred)
prev


# # 16) Modelo 03 - KNN Regressor

# In[65]:


from sklearn.neighbors import KNeighborsRegressor

modelo_KNN_regressor = KNeighborsRegressor(n_neighbors = 30, metric = 'euclidean')
modelo_KNN_regressor_fit = modelo_KNN_regressor.fit(x_train, y_train)
modelo_KNN_regressor_score = modelo_KNN_regressor.score(x_train, y_train)

print("Modelo - K-NN regressor score: %.2f" % (modelo_KNN_regressor_score * 100))


# In[66]:


modelo_KNN_regressor_pred = modelo_KNN_regressor.predict(x_test)
modelo_KNN_regressor_pred


# In[67]:


# O coeficiente de determina√ß√£o (R¬≤) √© uma medida resumida que diz quanto a linha de regress√£o ajusta-se aos dados. 
# √â um valor entra 0 e 1.

print('R¬≤ = {}'.format(modelo_KNN_regressor.score(x_train, y_train).round(2)))


# In[68]:


# Previs√£o do modelo 
pred = modelo_KNN_regressor.predict(x_train)
pred2 = y_train - pred
pred2


# In[69]:


# Grafico de regress√£o linear

plt.figure(figsize=(18, 8))
plt.scatter(pred, y_train)
plt.plot(pred, modelo_KNN_regressor.predict(x_train), color = "red")
plt.title("Grafico de regress√£o linear", fontsize = 20)
plt.xlabel("Total")
plt.xlabel("Total")
plt.ylabel("Valor dos im√≥veis")
plt.legend(["Pre√ßo", "Im√≥vel"])


# In[70]:


# Gr√°fico de distribui√ß√£o Frequ√™ncias

ax = sns.distplot(pred)
ax.figure.set_size_inches(20, 8)
ax.set_title('Distribui√ß√£o de Frequ√™ncias dos Res√≠duos', fontsize=18)
ax.set_xlabel('Valor', fontsize=14)
ax


# # 17) M√©tricas para o modelo 3 K-NN Regressor
# 
# - RMSE: Raiz do erro quadr√°tico m√©dio 
# - MAE: Erro absoluto m√©dio  
# - MSE: Erro m√©dio quadr√°tico
# - MAPE: Erro Percentual Absoluto M√©dio
# - R2: O R-Quadrado, ou Coeficiente de Determina√ß√£o, √© uma m√©trica que visa expressar a quantidade da varian√ßa dos dados.

# In[71]:


rmse = np.sqrt(mean_squared_error(y_test, modelo_KNN_regressor_pred))
mae = mean_absolute_error(y_test, modelo_KNN_regressor_pred)
mape = mean_absolute_percentage_error(y_test, modelo_KNN_regressor_pred)
mse = mean_squared_error(y_test, modelo_KNN_regressor_pred)
r2 = r2_score(y_test, modelo_KNN_regressor_pred)

pd.DataFrame([rmse, mae, mse, mape, r2], ['RMSE', 'MAE', 'MSE', "MAPE",'R¬≤'], columns=['Resultado'])


# In[72]:


# Previs√£o de im√≥vel

prev = x_test[0:25]
model_pred = modelo_KNN_regressor.predict(prev)[0]
print("Previs√£o de im√≥vel", model_pred)
prev


# # 18) Modelo 04 - Decision Tree Regressor

# In[73]:


from sklearn.tree import DecisionTreeRegressor

model_decision_tree_regressor = DecisionTreeRegressor(random_state = 30)
model_decision_tree_regressor_fit = model_decision_tree_regressor.fit(x_train, y_train)
model_decision_tree_regressor_score = model_decision_tree_regressor.score(x_train, y_train)

print("Modelo - Decision tree regressor score: %.2f" % (model_decision_tree_regressor_score * 100))


# In[74]:


model_decision_tree_regressor_pred = model_decision_tree_regressor.predict(x_test)
model_decision_tree_regressor_pred


# In[75]:


# O coeficiente de determina√ß√£o (R¬≤) √© uma medida resumida que diz quanto a linha de regress√£o ajusta-se aos dados. 
# √â um valor entra 0 e 1.

print('R¬≤ = {}'.format(model_decision_tree_regressor.score(x_train, y_train).round(2)))


# In[76]:


# Previs√£o do modelo 
pred = model_decision_tree_regressor.predict(x_train)
pred2 = y_train - pred
pred2


# In[77]:


# Grafico de regress√£o linear

plt.figure(figsize=(18, 8))
plt.scatter(pred, y_train)
plt.plot(pred, model_decision_tree_regressor.predict(x_train), color = "red")
plt.title("Grafico de regress√£o linear", fontsize = 20)
plt.xlabel("Total")
plt.xlabel("Total")
plt.ylabel("Valor dos im√≥veis")
plt.legend(["Pre√ßo", "Im√≥vel"])


# In[78]:


# Gr√°fico de distribui√ß√£o Frequ√™ncias

ax = sns.distplot(pred)
ax.figure.set_size_inches(20, 8)
ax.set_title('Distribui√ß√£o de Frequ√™ncias dos Res√≠duos', fontsize=18)
ax.set_xlabel('Valor', fontsize=14)
ax


# # 19) M√©tricas para o modelo 4 Decision Tree Regressor
# 
# - RMSE: Raiz do erro quadr√°tico m√©dio
# - MAE: Erro absoluto m√©dio
# - MSE: Erro m√©dio quadr√°tico
# - MAPE: Erro Percentual Absoluto M√©dio
# - R2: O R-Quadrado, ou Coeficiente de Determina√ß√£o, √© uma m√©trica que visa expressar a quantidade da varian√ßa dos dados.

# In[79]:


rmse = np.sqrt(mean_squared_error(y_test, model_decision_tree_regressor_pred))
mae = mean_absolute_error(y_test, model_decision_tree_regressor_pred)
mape = mean_absolute_percentage_error(y_test, model_decision_tree_regressor_pred)
mse = mean_squared_error(y_test, model_decision_tree_regressor_pred)
r2 = r2_score(y_test, model_decision_tree_regressor_pred)

pd.DataFrame([rmse, mae, mse, mape, r2], ['RMSE', 'MAE', 'MSE', "MAPE",'R¬≤'], columns=['Resultado'])


# In[80]:


# Previs√£o de im√≥vel

prev = x_test[0:25]
model_pred = model_decision_tree_regressor.predict(prev)[0]
print("Previs√£o de im√≥vel", model_pred)
prev


# # 20) Resultados final dos modelos

# In[81]:


# Exibindo um comparativo dos modelos de regress√£o linear

modelos = pd.DataFrame({
    
    "Modelos" :["Modelo Regress√£o Linear", 
                "Modelo Random Forest", 
                "Modelo K-NN Regressor",
                "Modelo Decision Tree Regressor"],

    "Acur√°cia" :[model_linear_score_1, 
                 model_random_forest_regressor_score, 
                 modelo_KNN_regressor_score,
                 model_decision_tree_regressor_score]})

modelos.sort_values(by = "Acur√°cia", ascending = False)


# # 21) Salvando modelo de ML

# In[82]:


# Salvando modelo de regress√£o linear

import pickle

with open('model_linear_pred.pkl', 'wb') as file:
    pickle.dump(model_linear_pred, file)
    
with open('model_random_forest_regressor_pred.pkl', 'wb') as file:
    pickle.dump(model_random_forest_regressor_pred, file)
    
with open('modelo_KNN_regressor_pred.pkl', 'wb') as file:
    pickle.dump(modelo_KNN_regressor_pred, file)
    
with open('model_decision_tree_regressor_pred.pkl', 'wb') as file:
    pickle.dump(model_decision_tree_regressor_pred, file)


# # 22) Conclus√£o do modelo machine learning

# Pela an√°lise dos modelos, modelo 1 decision tree regressor, e o segundo modelo random forest teve melhor resultado que os demais, atigindo uma acur√°cia de 95.53% para decision tree, random forest de 82.25% ou seja capaz de acertar as previs√µes de valor do im√≥vel. De acordo com an√°lise realizada.  

# # 23) Refer√™ncia 

# **Data Processing**
# 
# https://towardsdatascience.com/introduction-to-data-preprocessing-in-machine-learning-a9fa83a5dc9d
# 
# **Feature Engineering**
# 
# https://ateliware.com/blog/feature-engineering
# 
# **Escalonamento**
# 
# https://www.brutalk.com/en/news/brutalk-blog/view/como-usar-o-escalonamento-de-dados-melhorar-a-estabilidade-e-o-desempenho-do-modelo-de-aprendizado-profundo-6046ffa588320

# In[ ]:




